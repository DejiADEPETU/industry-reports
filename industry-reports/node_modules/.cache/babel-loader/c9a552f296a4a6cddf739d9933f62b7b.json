{"ast":null,"code":"var _jsxFileName = \"/Users/Student_M7/Desktop/SE/myGitHub/industry-reports/industry-reports/src/components/Home.js\";\nimport React from 'react';\nimport '../styles/Home.css';\nexport default function Home() {\n  return /*#__PURE__*/React.createElement(React.Fragment, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 5,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"div\", {\n    className: \"home-container\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 6,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 8,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"h3\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 9,\n      columnNumber: 21\n    }\n  }, \"INTRODUCTION\")), /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 14,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 15,\n      columnNumber: 21\n    }\n  }, \"Can international human rights help guide and govern artificial intelligence (AI)? According to the global ethics initiative of the Institute of Electrical and Electronics Engineers (IEEE), the largest organization of technical professionals, the answer is clear. The IEEE\\u2019s 2017 report on ethically aligned design for AI lists as its first principle that AI design should not infringe upon international human rights.1 Yet some AI sys- tems are already infringing on such rights. For instance, in March 2018, human rights investigators from the United Nations (UN) found that Facebook \\u2013 and its algorithmi- cally driven news feed \\u2013 exacerbated the circulation of hate speech and incitement to violence in Myanmar.2 During a US Congressional hearing in April 2018, Senator Pat- rick Leahy questioned CEO Mark Zuckerberg about the failure of Facebook\\u2019s AI for content detection in the face of possible genocide against Myanmar\\u2019s Rohingya ethic minority. While Zuckerberg initially told senators that more advanced AI tools would help solve the problem, he later conceded to investors that Facebook\\u2019s AI systems will be unable to detect \\u201Chate\\u201D in local contexts with reasonable accuracy anytime soon.3 Just a month after Zuckerberg\\u2019s hearing, the UN\\u2019s International Telecommunications Union (ITU) hosted its second annual AI for Global Good summit in Geneva.4 For many involved in the summit, AI is not just a source of potential risks, it can bring a better future of worldwide benefits. Between these hopes and fears lies an increased sense of uncertainty. As stakeholders look for a North Star to guide AI development, we can rely on human rights to help chart the course ahead. Simply put:\")), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"ConclusionImage1\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 44,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"img\", {\n    className: \"imageCon1\",\n    src: \"https://www.canterbury.ac.nz/engineering/schools/csse/research/ai/Brain-image-on-a-circuit-board_4014951147079649991.jpg\",\n    height: \"200px\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 45,\n      columnNumber: 17\n    }\n  })), /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 49,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 50,\n      columnNumber: 21\n    }\n  }, \"In order for AI to benefit the common good, at the very least its design and deployment should avoid harms to fundamental human values. International human rights provide a robust and global formulation of those values.\")), /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 59,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 60,\n      columnNumber: 21\n    }\n  }, \"In bridging AI and human rights, what\\u2019s at stake is human dignity.* As an international framework, human rights law is intended to establish global principles (\\u201Cnorms\\u201D) and mechanisms of accountability for the treatment of individuals. As such, a rights-based\")), /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 67,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"h4\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 68,\n      columnNumber: 21\n    }\n  }, \"GOVERNING ARTIFICIAL INTELLIGENCE\")), /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 73,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 74,\n      columnNumber: 21\n    }\n  }, \"approach provides actors developing AI with the aspirational and normative guid- ance to uphold human dignity and the inherent worth of every individual, regardless of country or jurisdiction. Implementing human rights can help identify and anticipate some of AI\\u2019s worst social harms and guide those developing technical and policy safe- guards to promote positive uses. Those working on AI accountability can activate the international system of human rights practice \\u2013 including binding treaties, UN investi- gations, and advocacy initiatives \\u2013 to monitor social impacts and establish processes of redress. Importantly, advocates can use human rights to focus attention on power relationships and inequalities that impact vulnerable or marginalized groups around the globe.\")), /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 93,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"h2\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 94,\n      columnNumber: 21\n    }\n  }, \"IMPLEMENTING HUMAN RIGHTS CAN HELP IDENTIFY AND ANTICIPATE SOME OF AI\\u2019S WORST SOCIAL HARMS AND GUIDE THOSE DEVELOPING TECHNICAL AND POLICY SAFEGUARDS TO PROMOTE POSITIVE USES.\")), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"ConclusionImage1\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 103,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"img\", {\n    className: \"imageCon1\",\n    src: \"https://news.blrstage.com/app/uploads/sites/3/2018/11/AI-Machine-Learning-5.jpg\",\n    height: \"200px\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 104,\n      columnNumber: 17\n    }\n  })), /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 109,\n      columnNumber: 17\n    }\n  }, /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 110,\n      columnNumber: 21\n    }\n  }, \"Those working on AI commercially might wonder why they should care about human rights. Increasingly, stakeholders are holding the private sector responsible for up- holding rights.5 In 2011, the UN released a landmark document \\u2013 The Guiding Princi- ples on Business and Human Rights \\u2013 that calls on industry to respect, protect, and provide remedies for human rights.6 These principles can provide AI executives and developers alike with a template for conducting due diligence on human rights im- pacts. They provide guidelines for how businesses should assume a higher duty of care when developing and deploying their products.7 Although a milestone in the field of business and human rights, the UN Guiding Princi- ples reflects but a starting point for the application of human rights in the tech sector. Those working directly on AI need regulation, or \\u201Chard\\u201D laws, along with technical standards, social norms, and market incentives, to effectively incorporate a respect for human rights into their business models, policies, and practices. At the same time, those working on human rights need to be actively engaged in AI governance and monitoring. When necessary, they should be ready to invoke a human rights frame- work to challenge how AI is developed and deployed by business or government. Civil society and AI developers should work together to help assess risk areas and antici- pate the needs of vulnerable groups. Only when stakeholders are working across silos to safeguard against harms can AI systems avoid human rights abuses and advance the enjoyment of human rights. This report is intended as a resource for anyone working in the field of AI and gover- nance. Anywhere that AI is being researched, developed, or deployed, a human rights frame can identify, anticipate, and minimize an important class of risks and harms. This work is also intended for those in the human rights field, outlining why they should be concerned about the present and near-term impacts of AI. What follows translates between these fields by reframing the societal impact of AI systems through the lens of human rights. For those seeking to govern AI \\u2013 from governments looking to craft regulation to companies looking to self-regulate \\u2013 this document offers a perspective based on established human rights accountability and norms. The field of human rights has lim- itations and will certainly not address all the ethical issues arising from AI. Yet it offers a strong value proposition: an approach to AI governance that upholds human dignity based on international human rights law. The first part of this report, \\u201CBridging AI and Human Rights,\\u201D connects the entry points between AI and human rights for governance discussions. Next, \\u201CA Human Rights Frame for AI Risks and Harms\\u201D reviews a number of current AI risks and harms from a human rights perspective, describing how such rights can be applied. Part three, \\u201CStakeholder Overview,\\u201D catalogues the current state of play among stakeholders active in this space, with examples of progress and challenges. Finally, the conclusion discusses the limitations and presents several recommendations for incorporating a human rights approach for AI governance.\")), /*#__PURE__*/React.createElement(\"h3\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 169,\n      columnNumber: 13\n    }\n  }, \"BRIDGING AI AND HUMAN RIGHTS\"), /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 174,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 175,\n      columnNumber: 17\n    }\n  }, \"Human rights have only appeared at the periphery of our prominent AI debates.8 Both AI and human rights are highly technical fields; to fully digest either would require far more of an exegesis than can be attempted in this report. Instead, we shall draw on basic entry points from both fields to inform AI governance discussions. Discussions about AI can be fragmented; some people speak of AI colloquially in the popular press or in tech marketing materials, while others speak of concrete methods in scientific proceedings.9 Moreover, the nuances of terminology and the speed at which the field is moving can make cross-disciplinary discussions difficult to have. When considering social and policy implications, it is useful to think of \\u201CAI\\u201D as a catchphrase for a cluster of technologies embedded in social systems. This includes machine learning, natural language processing, computer vision, neural networks, deep learning, big data analytics, predictive models, algorithms, and robotics\\u2014all of which are intrinsically situated in the social contexts where they are developed and deployed. While some areas of AI remain only theoretical, others, such as machine learning, are already having an impact in real-world contexts.10 Machine learning systems process large amounts of historical training data and \\u201Clearn\\u201D from these examples to detect patterns that can be useful in decision-making.11 All machine learning algorithms contain some level of statistical bias, which produces incorrect decisions some of the time.12 However, if the historical data are incomplete or are not representative of a specified population, these biases can scale quickly and inexplicably across AI systems. Such systems can further entrench discriminatory outcomes in people\\u2019s lives.\"), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"ConclusionImage1\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 200,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"img\", {\n    className: \"imageCon1\",\n    src: \"https://h2q8k3x8.stackpathcdn.com/wp-content/uploads/2017/05/artificial-intelligence-robot-ai.jpg\",\n    height: \"200px\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 201,\n      columnNumber: 17\n    }\n  })), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 205,\n      columnNumber: 13\n    }\n  }, \"How far should we as a society allow machine learning systems to influence human decision-making or even make decisions on their own? These concerns are at the heart of AI debates.13 While these questions have yet to be answered, the fact is that today, automated systems are making predictions about human behavior and producing decisions and recommendations that are impacting people in everyday life. These systems are increasingly becoming embedded in a number of social contexts, from policing and judicial sentencing to medicine and finance. We do not know the unintentional impacts or unforeseen consequences of current or future AI systems. As this uncertainty has brought urgent calls to govern AI, we can now turn to the value of human rights. The field of human rights can be complex for nonexperts. For the purposes of this report, we anchor international human rights law in the drafting and implementation of the Universal Declaration on Human Rights (UDHR) by the United Nations in 1948. The UDHR\\u2019s aspirational language established that human rights were grounded in a respect for all individuals that derived from our equal status as bearers of inherent human dignity. This was a response to the \\u201Cdisregard and contempt for human rights,\\u201D14 which precipitated two world wars and the Holocaust. Human dignity and fundamen- tal rights are not tied to country citizenship, legal regime, or socioeconomic position. These rights are universal in the sense that they apply to everyone, everywhere, which provides a frame for discussing global AI impact and governance. Over the last 70 years, human rights proponents have developed the principles of the UDHR into a body of international human rights law that includes nine major human rights treaties; regional rights instruments in the Americas, Africa, and Europe; incor- poration in state constitutions and national laws; and customary and case law.15 Yet because of a divergence in political ideologies and claims to sovereignty, governments enforce international human rights law to wildly varying degrees.16 Thus, a human rights framework has emerged to monitor, promote, and protect human rights. This involves the further development of international human rights law and the interaction of a diverse network of actors in the UN system, nation-states, international organiza- tions, NGOs, civil society, the private sector, academia, and advocates at the local or individual level. Those looking for first principles to ground AI governance can use the language of human rights. For example, one of the most hotly debated topics in AI is discrimina- tory algorithms and systems. This includes empirical research on facial recognition systems that cannot \\u201Csee\\u201D people, particularly women, with darker skin due to a lack of adequate training data or to faulty models and therefore reproduce culturally en- grained biases against people of color.17 Human rights principles of nondiscrimination have been propagated through a multitude of UN treaties, national laws, UN commen- tary, academic interpretation, and other policies and guidelines. This body of work offers not only a distinct value commitment but also a global perspective on how to identify the impact of discrimination. Equality and nondiscrimination are foundational to practically every major human rights instrument that has emerged from debate and input from representatives from the world\\u2019s nations. The development of human rights has its own controversies and politics, but over the last 70 years, international human rights have come to represent shared global values. Those working on technology policy are faced with the difficult task of deciding what standards, values, or norms to apply in different social contexts. They need to balance the tradeoffs of developing or deploying technologies. They need to understand the potential misuses and abuses, unintended consequences, biases in sociotechnical systems, and even the costs of not deploying a tool when it may help someone in need. Human rights provide those working on AI with a basis for understanding why governing systems \\u2013 from technical standards to policy \\u2013 should address values like nondiscrimination in the first place. This is important for tech companies whose prod- ucts will be used across national borders where laws and values vary. While it is outside the present scope of this report, an area that demands more foun- dational work concerns pathways for human rights accountability and remedy when AI harms become manifest. A purely legal, regulatory, or compliance framework would lag behind the velocity of change associated with emerging AI technologies. Thus, other components of the human rights framework, such as UN special rapporteurs, independent investigators, and monitors from civil society are crucial for calling attention to AI risks and harms. As scholars Christiaan Van Veen of New York Univer- sity (NYU) and Corinne Cath of Oxford Internet Institute state, \\u201CHuman rights, as a language and legal framework, is itself a source of power because human rights carry significant moral legitimacy and the reputational cost of being perceived as a human rights violator can be very high.\\u201D18 Thus, human rights can provide the link between an AI system\\u2019s negative social impact on even one individual in places like Myanmar and the most powerful companies in Silicon Valley.\"))));\n}","map":{"version":3,"sources":["/Users/Student_M7/Desktop/SE/myGitHub/industry-reports/industry-reports/src/components/Home.js"],"names":["React","Home"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,OAAO,oBAAP;AACI,eAAe,SAASC,IAAT,GAAgB;AAC3B,sBACI,oBAAC,KAAD,CAAO,QAAP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAK,IAAA,SAAS,EAAC,gBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBADJ,CAFA,eAQA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qtDADJ,CARA,eAsCA;AAAK,IAAA,SAAS,EAAC,kBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACA;AAAK,IAAA,SAAS,EAAC,WAAf;AAA2B,IAAA,GAAG,EAAC,0HAA/B;AAA0J,IAAA,MAAM,EAAC,OAAjK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADA,CAtCA,eA2CA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mOADJ,CA3CA,eAqDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0RADJ,CArDA,eA6DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yCADJ,CA7DA,eAmEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8xBADJ,CAnEA,eAuFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4LADJ,CAvFA,eAiGA;AAAK,IAAA,SAAS,EAAC,kBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACA;AAAK,IAAA,SAAS,EAAC,WAAf;AAA2B,IAAA,GAAG,EAAC,iFAA/B;AAAiH,IAAA,MAAM,EAAC,OAAxH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADA,CAjGA,eAuGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+sGADJ,CAvGA,eAmKJ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oCAnKI,eAwKJ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,ixDADJ,eA0BA;AAAK,IAAA,SAAS,EAAC,kBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI;AAAK,IAAA,SAAS,EAAC,WAAf;AAA2B,IAAA,GAAG,EAAC,mGAA/B;AAAmI,IAAA,MAAM,EAAC,OAA1I;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADJ,CA1BA,eA+BA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,w1KA/BA,CAxKI,CADJ,CADJ;AAqSP","sourcesContent":["import React from 'react'\nimport '../styles/Home.css';\n    export default function Home() {\n        return (\n            <React.Fragment>\n                <div className=\"home-container\">\n                        \n                <div>\n                    <h3>\n                    INTRODUCTION\n                    </h3>\n                </div>\n\n                <div>\n                    <p>\n                    Can international human rights help guide and govern artificial intelligence (AI)?\n                    According to the global ethics initiative of the Institute of Electrical and Electronics\n                    Engineers (IEEE), the largest organization of technical professionals, the answer is\n                    clear. The IEEE’s 2017 report on ethically aligned design for AI lists as its first principle\n                    that AI design should not infringe upon international human rights.1\n\n                    Yet some AI sys-\n                    tems are already infringing on such rights. For instance, in March 2018, human rights\n\n                    investigators from the United Nations (UN) found that Facebook – and its algorithmi-\n                    cally driven news feed – exacerbated the circulation of hate speech and incitement to\n\n                    violence in Myanmar.2 During a US Congressional hearing in April 2018, Senator Pat-\n                    rick Leahy questioned CEO Mark Zuckerberg about the failure of Facebook’s AI for\n\n                    content detection in the face of possible genocide against Myanmar’s Rohingya ethic\n                    minority. While Zuckerberg initially told senators that more advanced AI tools would\n                    help solve the problem, he later conceded to investors that Facebook’s AI systems will\n                    be unable to detect “hate” in local contexts with reasonable accuracy anytime soon.3\n                    Just a month after Zuckerberg’s hearing, the UN’s International Telecommunications\n                    Union (ITU) hosted its second annual AI for Global Good summit in Geneva.4 For many\n                    involved in the summit, AI is not just a source of potential risks, it can bring a better\n                    future of worldwide benefits. Between these hopes and fears lies an increased sense\n                    of uncertainty. As stakeholders look for a North Star to guide AI development, we can\n                    rely on human rights to help chart the course ahead. Simply put:\n                    </p>\n                </div>\n\n                <div className=\"ConclusionImage1\">\n                <img className=\"imageCon1\" src=\"https://www.canterbury.ac.nz/engineering/schools/csse/research/ai/Brain-image-on-a-circuit-board_4014951147079649991.jpg\" height=\"200px\"/>\n                </div>\n                \n\n                <div>\n                    <p>\n                    In order for AI to benefit the common good, at the very least its\n                    design and deployment should avoid harms to fundamental human\n                    values. International human rights provide a robust and global\n                    formulation of those values.\n\n                    </p>\n                </div>\n\n                <div>\n                    <p>\n                    In bridging AI and human rights, what’s at stake is human dignity.* As an international\n                    framework, human rights law is intended to establish global principles (“norms”) and\n                    mechanisms of accountability for the treatment of individuals. As such, a rights-based\n                    </p>\n                </div>\n        \n                <div>\n                    <h4>\n                    GOVERNING ARTIFICIAL INTELLIGENCE\n                    </h4>               \n                </div>\n\n                <div>\n                    <p>\n                    approach provides actors developing AI with the aspirational and normative guid-\n                    ance to uphold human dignity and the inherent worth of every individual, regardless\n\n                    of country or jurisdiction. Implementing human rights can help identify and anticipate\n\n                    some of AI’s worst social harms and guide those developing technical and policy safe-\n                    guards to promote positive uses. Those working on AI accountability can activate the\n\n                    international system of human rights practice – including binding treaties, UN investi-\n                    gations, and advocacy initiatives – to monitor social impacts and establish processes\n\n                    of redress. Importantly, advocates can use human rights to focus attention on power\n                    relationships and inequalities that impact vulnerable or marginalized groups around\n                    the globe.\n                    </p>\n                </div>\n        \n\n                <div>\n                    <h2>\n                    IMPLEMENTING HUMAN RIGHTS CAN HELP\n                    IDENTIFY AND ANTICIPATE SOME OF AI’S WORST\n                    SOCIAL HARMS AND GUIDE THOSE DEVELOPING\n                    TECHNICAL AND POLICY SAFEGUARDS TO\n                    PROMOTE POSITIVE USES.\n                    </h2>\n                </div>\n\n                <div className=\"ConclusionImage1\">\n                <img className=\"imageCon1\" src=\"https://news.blrstage.com/app/uploads/sites/3/2018/11/AI-Machine-Learning-5.jpg\" height=\"200px\"/>\n                </div>\n            \n        \n\n                <div>\n                    <p>\n                    Those working on AI commercially might wonder why they should care about human\n\n                    rights. Increasingly, stakeholders are holding the private sector responsible for up-\n                    holding rights.5 In 2011, the UN released a landmark document – The Guiding Princi-\n                    ples on Business and Human Rights – that calls on industry to respect, protect, and\n\n                    provide remedies for human rights.6 These principles can provide AI executives and\n\n                    developers alike with a template for conducting due diligence on human rights im-\n                    pacts. They provide guidelines for how businesses should assume a higher duty of\n\n                    care when developing and deploying their products.7\n\n                    Although a milestone in the field of business and human rights, the UN Guiding Princi-\n                    ples reflects but a starting point for the application of human rights in the tech sector.\n\n                    Those working directly on AI need regulation, or “hard” laws, along with technical\n                    standards, social norms, and market incentives, to effectively incorporate a respect\n                    for human rights into their business models, policies, and practices. At the same time,\n                    those working on human rights need to be actively engaged in AI governance and\n\n                    monitoring. When necessary, they should be ready to invoke a human rights frame-\n                    work to challenge how AI is developed and deployed by business or government. Civil\n\n                    society and AI developers should work together to help assess risk areas and antici-\n                    pate the needs of vulnerable groups. Only when stakeholders are working across silos\n\n                    to safeguard against harms can AI systems avoid human rights abuses and advance\n                    the enjoyment of human rights.\n\n                    This report is intended as a resource for anyone working in the field of AI and gover-\n                    nance. Anywhere that AI is being researched, developed, or deployed, a human rights\n\n                    frame can identify, anticipate, and minimize an important class of risks and harms. This\n                    work is also intended for those in the human rights field, outlining why they should be\n                    concerned about the present and near-term impacts of AI. What follows translates\n                    between these fields by reframing the societal impact of AI systems through the lens\n                    of human rights.\n                    For those seeking to govern AI – from governments looking to craft regulation to\n                    companies looking to self-regulate – this document offers a perspective based on\n\n                    established human rights accountability and norms. The field of human rights has lim-\n                    itations and will certainly not address all the ethical issues arising from AI. Yet it offers\n\n                    a strong value proposition: an approach to AI governance that upholds human dignity\n                    based on international human rights law.\n                    The first part of this report, “Bridging AI and Human Rights,” connects the entry points\n                    between AI and human rights for governance discussions. Next, “A Human Rights\n                    Frame for AI Risks and Harms” reviews a number of current AI risks and harms from\n                    a human rights perspective, describing how such rights can be applied. Part three,\n                    “Stakeholder Overview,” catalogues the current state of play among stakeholders\n                    active in this space, with examples of progress and challenges. Finally, the conclusion\n                    discusses the limitations and presents several recommendations for incorporating a\n                    human rights approach for AI governance.\n                        </p>\n                    </div>\n        \n\n            <h3>\n            BRIDGING AI AND HUMAN RIGHTS\n            </h3>\n\n\n            <div>\n                <p>\n            Human rights have only appeared at the periphery of our prominent AI debates.8 Both\n            AI and human rights are highly technical fields; to fully digest either would require far\n            more of an exegesis than can be attempted in this report. Instead, we shall draw on\n            basic entry points from both fields to inform AI governance discussions.\n            Discussions about AI can be fragmented; some people speak of AI colloquially in\n            the popular press or in tech marketing materials, while others speak of concrete\n            methods in scientific proceedings.9 Moreover, the nuances of terminology and the\n            speed at which the field is moving can make cross-disciplinary discussions difficult to\n            have. When considering social and policy implications, it is useful to think of “AI” as a\n            catchphrase for a cluster of technologies embedded in social systems. This includes\n            machine learning, natural language processing, computer vision, neural networks,\n            deep learning, big data analytics, predictive models, algorithms, and robotics—all of\n            which are intrinsically situated in the social contexts where they are developed and\n            deployed.\n            While some areas of AI remain only theoretical, others, such as machine learning, are\n            already having an impact in real-world contexts.10 Machine learning systems process\n            large amounts of historical training data and “learn” from these examples to detect\n            patterns that can be useful in decision-making.11 All machine learning algorithms\n            contain some level of statistical bias, which produces incorrect decisions some of\n            the time.12 However, if the historical data are incomplete or are not representative\n            of a specified population, these biases can scale quickly and inexplicably across \n            AI systems. Such systems can further entrench discriminatory outcomes in people’s lives.\n            </p>\n\n            <div className=\"ConclusionImage1\">\n                <img className=\"imageCon1\" src=\"https://h2q8k3x8.stackpathcdn.com/wp-content/uploads/2017/05/artificial-intelligence-robot-ai.jpg\" height=\"200px\"/>\n            </div>\n\n\n            <p>\n            \n\n\n                    How far should we as a society allow machine learning systems to influence human\n                    decision-making or even make decisions on their own? These concerns are at the\n                    heart of AI debates.13\n                    While these questions have yet to be answered, the fact is that today, automated\n                    systems are making predictions about human behavior and producing decisions and\n                    recommendations that are impacting people in everyday life. These systems are\n                    increasingly becoming embedded in a number of social contexts, from policing and\n                    judicial sentencing to medicine and finance. We do not know the unintentional impacts\n                    or unforeseen consequences of current or future AI systems. As this uncertainty has\n                    brought urgent calls to govern AI, we can now turn to the value of human rights.\n                    The field of human rights can be complex for nonexperts. For the purposes of this\n                    report, we anchor international human rights law in the drafting and implementation\n                    of the Universal Declaration on Human Rights (UDHR) by the United Nations in 1948.\n                    The UDHR’s aspirational language established that human rights were grounded in a\n\n                    respect for all individuals that derived from our equal status as bearers of inherent human dignity. This was a response to the “disregard and contempt for human rights,”14\n\n                    which precipitated two world wars and the Holocaust. Human dignity and fundamen-\n                    tal rights are not tied to country citizenship, legal regime, or socioeconomic position.\n\n                    These rights are universal in the sense that they apply to everyone, everywhere, which\n                    provides a frame for discussing global AI impact and governance.\n                    Over the last 70 years, human rights proponents have developed the principles of the\n                    UDHR into a body of international human rights law that includes nine major human\n\n                    rights treaties; regional rights instruments in the Americas, Africa, and Europe; incor-\n                    poration in state constitutions and national laws; and customary and case law.15 Yet\n\n                    because of a divergence in political ideologies and claims to sovereignty, governments\n                    enforce international human rights law to wildly varying degrees.16 Thus, a human\n                    rights framework has emerged to monitor, promote, and protect human rights. This\n                    involves the further development of international human rights law and the interaction\n                    of a diverse network of actors in the UN system, nation-states, international organiza-\n                    tions, NGOs, civil society, the private sector, academia, and advocates at the local or\n\n                    individual level.\n                    Those looking for first principles to ground AI governance can use the language of\n\n                    human rights. For example, one of the most hotly debated topics in AI is discrimina-\n                    tory algorithms and systems. This includes empirical research on facial recognition\n\n                    systems that cannot “see” people, particularly women, with darker skin due to a lack\n\n                    of adequate training data or to faulty models and therefore reproduce culturally en-\n                    grained biases against people of color.17 Human rights principles of nondiscrimination\n\n                    have been propagated through a multitude of UN treaties, national laws, UN commen-\n                    tary, academic interpretation, and other policies and guidelines. This body of work\n\n                    offers not only a distinct value commitment but also a global perspective on how to\n                    identify the impact of discrimination. Equality and nondiscrimination are foundational\n                    to practically every major human rights instrument that has emerged from debate and\n                    input from representatives from the world’s nations. The development of human rights\n                    has its own controversies and politics, but over the last 70 years, international human\n                    rights have come to represent shared global values.\n                    Those working on technology policy are faced with the difficult task of deciding what\n                    standards, values, or norms to apply in different social contexts. They need to balance\n                    the tradeoffs of developing or deploying technologies. They need to understand the\n                    potential misuses and abuses, unintended consequences, biases in sociotechnical\n                    systems, and even the costs of not deploying a tool when it may help someone in\n                    \n                    need. Human rights provide those working on AI with a basis for understanding why\n                    governing systems – from technical standards to policy – should address values like\n\n                    nondiscrimination in the first place. This is important for tech companies whose prod-\n                    ucts will be used across national borders where laws and values vary.\n\n                    While it is outside the present scope of this report, an area that demands more foun-\n                    dational work concerns pathways for human rights accountability and remedy when\n\n                    AI harms become manifest. A purely legal, regulatory, or compliance framework would\n                    lag behind the velocity of change associated with emerging AI technologies. Thus,\n                    other components of the human rights framework, such as UN special rapporteurs,\n                    independent investigators, and monitors from civil society are crucial for calling\n\n                    attention to AI risks and harms. As scholars Christiaan Van Veen of New York Univer-\n                    sity (NYU) and Corinne Cath of Oxford Internet Institute state, “Human rights, as a\n\n                    language and legal framework, is itself a source of power because human rights carry\n                    significant moral legitimacy and the reputational cost of being perceived as a human\n                    rights violator can be very high.”18 Thus, human rights can provide the link between an\n                    AI system’s negative social impact on even one individual in places like Myanmar and\n                    the most powerful companies in Silicon Valley.\n                </p>\n            </div>\n            </div>\n        </React.Fragment>\n    )\n}\n"]},"metadata":{},"sourceType":"module"}